{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import PreTrainedModel, PretrainedConfig\n",
        "from safetensors.torch import save_file, load_file"
      ],
      "metadata": {
        "id": "uuxebiYldbe5"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MiniConfig(PretrainedConfig):\n",
        "    model_type = \"mini_transformer\"\n",
        "\n",
        "    def __init__(self, vocab_size=50, hidden_dim=32, num_heads=2, num_layers=1, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.vocab_size = vocab_size\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.num_layers = num_layers"
      ],
      "metadata": {
        "id": "O6ERgfpbdX86"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MiniTransformer(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(config.vocab_size, config.hidden_dim)\n",
        "        encoder_layer = nn.TransformerEncoderLayer(d_model=config.hidden_dim, nhead=config.num_heads)\n",
        "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=config.num_layers)\n",
        "        self.fc = nn.Linear(config.hidden_dim, config.vocab_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        x = self.encoder(x)\n",
        "        x = self.fc(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "8G9Mi1MIdlOz"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class HFMiniTransformer(PreTrainedModel):\n",
        "    config_class = MiniConfig\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "        self.model = MiniTransformer(config)\n",
        "\n",
        "    def forward(self, input_ids=None):\n",
        "        return self.model(input_ids)"
      ],
      "metadata": {
        "id": "t6oWSzOrdpBw"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts = [\"I love AI\", \"Transformers are great\", \"I hate bugs\", \"Debugging is fun\"]\n",
        "\n",
        "words = sorted(list(set(\" \".join(texts).split())))\n",
        "vocab = {word: idx for idx, word in enumerate(words)}\n",
        "\n",
        "def encode(text):\n",
        "    return torch.tensor([vocab[w] for w in text.split()])\n",
        "\n",
        "inputs = torch.nn.utils.rnn.pad_sequence([encode(t) for t in texts], batch_first=True)\n",
        "\n",
        "print(\"Vocabulary:\", vocab)\n",
        "print(\"Input tensor shape:\", inputs.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zFwktmeJsQFt",
        "outputId": "f33f4f6c-27ba-4e8d-e771-ff2b7179fd56"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary: {'AI': 0, 'Debugging': 1, 'I': 2, 'Transformers': 3, 'are': 4, 'bugs': 5, 'fun': 6, 'great': 7, 'hate': 8, 'is': 9, 'love': 10}\n",
            "Input tensor shape: torch.Size([4, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config = MiniConfig(vocab_size=len(vocab), hidden_dim=32, num_heads=2, num_layers=1)\n",
        "hf_model = HFMiniTransformer(config)\n",
        "\n",
        "output = hf_model(inputs)\n",
        "print(\"Output shape (batch_size, seq_len, vocab_size):\", output.shape)\n",
        "\n",
        "pred_ids = torch.argmax(output, dim=-1)\n",
        "print(\"Predicted token IDs:\\n\", pred_ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ssFFscfysTBX",
        "outputId": "88fb79af-aa7f-45a8-f091-18d37566df12"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output shape (batch_size, seq_len, vocab_size): torch.Size([4, 3, 11])\n",
            "Predicted token IDs:\n",
            " tensor([[ 9, 10,  9],\n",
            "        [10,  7,  4],\n",
            "        [ 3,  5,  3],\n",
            "        [ 1,  3,  0]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hf_model.save_pretrained(\"mini_transformer_demo\", safe_serialization=True)"
      ],
      "metadata": {
        "id": "JxQCO8B0sXRj"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model = HFMiniTransformer.from_pretrained(\"mini_transformer_demo\")\n",
        "loaded_model.eval()\n",
        "\n",
        "new_text = \"I love bugs\"\n",
        "new_input = torch.nn.utils.rnn.pad_sequence([encode(new_text)], batch_first=True)\n",
        "output_test = loaded_model(new_input)\n",
        "pred_ids_test = torch.argmax(output_test, dim=-1)\n",
        "print(\"Predicted token IDs for new sentence:\", pred_ids_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q0WfQgk3OYHO",
        "outputId": "f30397ee-21a8-4569-ecaa-35ee001b05ec"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted token IDs for new sentence: tensor([[10,  6,  1]])\n"
          ]
        }
      ]
    }
  ]
}